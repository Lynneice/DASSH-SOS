{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Sys_Fully_Populated.ipynb\n",
    "\n",
    "\n",
    "# Fully Populated SysAgent Architecture — Rebuilt from Design\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import hashlib\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegratedSelfObservationSystem:\n",
    "    def __init__(self, state_keys):\n",
    "        self.identity_trace = []\n",
    "        self.state = {k: 1.0 for k in state_keys}\n",
    "        self.state[\"existential_stability\"] = 1.0\n",
    "        self.state[\"metaphysical_checksum\"] = None\n",
    "        self.causal_engine = SimpleCausalEngine(state_keys)\n",
    "        self.state_keys = state_keys\n",
    "\n",
    "    def update(self, self_image: Dict):\n",
    "        self.identity_trace.append(self_image)\n",
    "        if len(self.identity_trace) > 5:\n",
    "            self.identity_trace = self.identity_trace[-5:]\n",
    "        self.state.update(self_image)\n",
    "        self.state[\"existential_stability\"] = self.assess_stability()\n",
    "        self.state[\"metaphysical_checksum\"] = self.hash_self_image(self_image)\n",
    "        self.causal_engine.log_state(self_image)\n",
    "\n",
    "    def assess_stability(self) -> float:\n",
    "        if len(self.identity_trace) < 2:\n",
    "            return 1.0\n",
    "        similarities = []\n",
    "        for i in range(len(self.identity_trace) - 1):\n",
    "            sim = self.compare_self_images(\n",
    "                self.identity_trace[i],\n",
    "                self.identity_trace[i + 1]\n",
    "            )\n",
    "            similarities.append(sim)\n",
    "        return float(np.clip(np.mean(similarities), 0.0, 1.0))\n",
    "\n",
    "    def compare_self_images(self, img1: Dict, img2: Dict) -> float:\n",
    "        keys = set(img1.keys()) | set(img2.keys())\n",
    "        diffs = 0\n",
    "        for key in keys:\n",
    "            v1 = img1.get(key, 0)\n",
    "            v2 = img2.get(key, 0)\n",
    "            diffs += abs(v1 - v2)\n",
    "        max_possible_diff = len(keys)\n",
    "        return 1.0 - (diffs / max_possible_diff)\n",
    "\n",
    "    def hash_self_image(self, self_image: Dict) -> str:\n",
    "        concat = ''.join(f\"{k}:{v}\" for k, v in sorted(self_image.items()))\n",
    "        return hashlib.sha256(concat.encode()).hexdigest()\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.state\n",
    "\n",
    "    def get_causal_prediction(self):\n",
    "        return self.causal_engine.predict_next()\n",
    "\n",
    "    def get_causal_error(self, actual_state: Dict):\n",
    "        return self.causal_engine.calculate_error(actual_state)\n",
    "    \n",
    "#instantiate the system with some example state keys\n",
    "state_keys = [\"hunger\", \"fatigue\", \"stress\", \"focus\", \"creativity\"]\n",
    "self_observation_system = IntegratedSelfObservationSystem(state_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hunger': 1.0, 'fatigue': 1.0, 'stress': 1.0, 'focus': 1.0, 'creativity': 1.0, 'existential_stability': 1.0, 'metaphysical_checksum': None}\n",
      "{'hunger': 0.8, 'fatigue': 0.5, 'stress': 0.3, 'focus': 0.9, 'creativity': 0.7, 'existential_stability': 1.0, 'metaphysical_checksum': '7bab37fb70d2264d273b97de85b096c8c62374023042ce662ecd485e713e64d2'}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(self_observation_system.get_state())\n",
    "# Example update\n",
    "self_observation_system.update({\n",
    "    \"hunger\": 0.8,\n",
    "    \"fatigue\": 0.5,\n",
    "    \"stress\": 0.3,\n",
    "    \"focus\": 0.9,\n",
    "    \"creativity\": 0.7\n",
    "})\n",
    "print(self_observation_system.get_state())\n",
    "print(self_observation_system.get_causal_prediction())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hunger': 0.6, 'fatigue': 0.4, 'stress': 0.2, 'focus': 0.95, 'creativity': 0.75, 'existential_stability': 0.95, 'metaphysical_checksum': '1358691e65365bc3d1d95163c0bf845532ec37522b7d55b450eab08f4d7349e3'}\n",
      "{'hunger': 0.6000000000000003, 'fatigue': 0.40000000000000013, 'stress': 0.20000000000000007, 'focus': 0.9500000000000001, 'creativity': 0.75}\n",
      "{'hunger': 0.09999999999999964, 'fatigue': 0.04999999999999988, 'stress': 0.04999999999999993, 'focus': 0.030000000000000027, 'creativity': 0.030000000000000027}\n"
     ]
    }
   ],
   "source": [
    "#self_observation_system test update\n",
    "self_observation_system.update({\n",
    "    \"hunger\": 0.6,\n",
    "    \"fatigue\": 0.4,\n",
    "    \"stress\": 0.2,\n",
    "    \"focus\": 0.95,\n",
    "    \"creativity\": 0.75\n",
    "})\n",
    "print(self_observation_system.get_state())\n",
    "print(self_observation_system.get_causal_prediction())\n",
    "print(self_observation_system.get_causal_error({\n",
    "    \"hunger\": 0.7,\n",
    "    \"fatigue\": 0.45,\n",
    "    \"stress\": 0.25,\n",
    "    \"focus\": 0.92,\n",
    "    \"creativity\": 0.72\n",
    "}))\n",
    "# More updates to see stability changes\n",
    "self_observation_system.update({\n",
    "    \"hunger\": 0.7,\n",
    "    \"fatigue\": 0.6,\n",
    "    \"stress\": 0.4,\n",
    "    \"focus\": 0.85,\n",
    "    \"creativity\": 0.8\n",
    "})\n",
    "# print(self_observation_system.get_state())\n",
    "# print(self_observation_system.get_causal_prediction())\n",
    "# print(self_observation_system.get_causal_error({\n",
    "#     \"hunger\": 0.65,\n",
    "#     \"fatigue\": 0.55,\n",
    "#     \"stress\": 0.35,\n",
    "#     \"focus\": 0.88,\n",
    "#     \"creativity\": 0.78\n",
    "# }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hunger': 0.7, 'fatigue': 0.6, 'stress': 0.4, 'focus': 0.85, 'creativity': 0.8, 'existential_stability': 0.9233333333333333, 'metaphysical_checksum': 'f56c6da6476e2ab67ed374e4c6554e10d49f2c7c62eb97e257a65d39a2fbcfb6'}\n"
     ]
    }
   ],
   "source": [
    "print(self_observation_system.get_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update sos memory to be compatible with rough memorybench functionality\n",
    "class MemoryStore:\n",
    "    def __init__(self):\n",
    "        self.client = chromadb.Client(Settings(chroma_db_impl=\"duckdb+parquet\", persist_directory=\".chromadb/\"))\n",
    "        self.collection = self.client.get_or_create_collection(name=\"self_observation_memory\")\n",
    "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    def store(self, text, metadata=None):\n",
    "        embedding = self.embedding_model.encode([text])[0].tolist()\n",
    "        # Use a hash of the text as a unique ID\n",
    "        doc_id = hashlib.sha256(text.encode()).hexdigest()\n",
    "        self.collection.add(\n",
    "            ids=[doc_id],\n",
    "            documents=[text],\n",
    "            metadatas=[metadata or {}],\n",
    "            embeddings=[embedding]\n",
    "        )\n",
    "    def query(self, text, top_k=3):\n",
    "        embedding = self.embedding_model.encode([text])[0].tolist()\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[embedding],\n",
    "            n_results=top_k\n",
    "        )\n",
    "        documents = results.get('documents')\n",
    "        if documents is None or not documents or documents[0] is None:\n",
    "            return []\n",
    "        return documents[0]\n",
    "  \n",
    "    # def __init__(self):\n",
    "    #     self.entries = []\n",
    "\n",
    "    # def store(self, text, metadata=None):\n",
    "    #     self.entries.append({\n",
    "    #         \"text\": text,\n",
    "    #         \"metadata\": metadata or {}\n",
    "    #     })\n",
    "\n",
    "    # def query(self, text, top_k=3):\n",
    "    #     query_keywords = set(text.lower().split())\n",
    "    #     scored = []\n",
    "    #     for entry in self.entries:\n",
    "    #         entry_keywords = set(entry[\"text\"].lower().split())\n",
    "    #         score = len(query_keywords & entry_keywords)\n",
    "    #         scored.append((score, entry))\n",
    "    #     top_matches = sorted(scored, key=lambda x: -x[0])[:top_k]\n",
    "    #     return [entry for score, entry in top_matches]\n",
    "    \n",
    "\n",
    "class MemoryBench:\n",
    "    def __init__(self, capacity=10):\n",
    "        self.capacity = capacity\n",
    "        self.entries = []\n",
    "    def store(self, text, metadata=None):\n",
    "        entry = {\n",
    "            \"text\": text,\n",
    "            \"metadata\": metadata or {}\n",
    "        }\n",
    "        self.entries.append(entry)\n",
    "        if len(self.entries) > self.capacity:\n",
    "            self.entries.pop(0)\n",
    "\n",
    "\n",
    "    def is_familiar(self, query_text):\n",
    "        query_keywords = set(query_text.lower().split())\n",
    "        scores = []\n",
    "        for entry in self.entries:\n",
    "            entry_keywords = set(entry[\"text\"].lower().split())\n",
    "            # score = len(query_keywords & entry_keywords) / len(query_keywords | entry_keywords)\n",
    "            score = len(query_keywords & entry_keywords)\n",
    "            scores.append((score, entry[\"text\"]))\n",
    "        if not scores:\n",
    "            return \"novel\", 0, None\n",
    "        best_score, best_match = max(scores, key=lambda x: x[0])\n",
    "        familiarity = \"familiar\" if best_score > 2 else \"novel\"\n",
    "        return familiarity, best_score, best_match\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## SelfObservationSystem\"\"\"\n",
    "\n",
    "class SelfObservationSystem:\n",
    "    def __init__(self):\n",
    "        self.identity_trace = []\n",
    "        self.state = {\n",
    "            \"existential_stability\": 1.0,\n",
    "            \"metaphysical_checksum\": None\n",
    "        }\n",
    "\n",
    "    def update(self, self_image: Dict):\n",
    "        self.identity_trace.append(self_image)\n",
    "        if len(self.identity_trace) > 5:\n",
    "            self.identity_trace = self.identity_trace[-5:]\n",
    "        self.state[\"existential_stability\"] = self.assess_stability()\n",
    "        self.state[\"metaphysical_checksum\"] = self.hash_self_image(self_image)\n",
    "\n",
    "    def assess_stability(self) -> float:\n",
    "        if len(self.identity_trace) < 2:\n",
    "            return 1.0\n",
    "        similarities = []\n",
    "        for i in range(len(self.identity_trace) - 1):\n",
    "            sim = self.compare_self_images(\n",
    "                self.identity_trace[i],\n",
    "                self.identity_trace[i + 1]\n",
    "            )\n",
    "            similarities.append(sim)\n",
    "        return float(np.clip(np.mean(similarities), 0.0, 1.0))\n",
    "\n",
    "    def compare_self_images(self, img1: Dict, img2: Dict) -> float:\n",
    "        keys = set(img1.keys()) | set(img2.keys())\n",
    "        diffs = 0\n",
    "        for key in keys:\n",
    "            v1 = img1.get(key, 0)\n",
    "            v2 = img2.get(key, 0)\n",
    "            diffs += abs(v1 - v2)\n",
    "        max_possible_diff = len(keys)\n",
    "        return 1.0 - (diffs / max_possible_diff)\n",
    "\n",
    "    def hash_self_image(self, self_image: Dict) -> str:\n",
    "        concat = ''.join(f\"{k}:{v}\" for k, v in sorted(self_image.items()))\n",
    "        return hashlib.sha256(concat.encode()).hexdigest()\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selfobservsystem test memory store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimulatedMemoryStore:\n",
    "#     def __init__(self):\n",
    "#         self.entries = []\n",
    "\n",
    "#     def store(self, text, metadata=None):\n",
    "#         self.entries.append({\n",
    "#             \"text\": text,\n",
    "#             \"metadata\": metadata or {}\n",
    "#         })\n",
    "\n",
    "#     def query(self, text, top_k=3):\n",
    "#         query_keywords = set(text.lower().split())\n",
    "#         scored = []\n",
    "#         for entry in self.entries:\n",
    "#             entry_keywords = set(entry[\"text\"].lower().split())\n",
    "#             score = len(query_keywords & entry_keywords)\n",
    "#             scored.append((score, entry))\n",
    "#         top_matches = sorted(scored, key=lambda x: -x[0])[:top_k]\n",
    "#         return [entry for score, entry in top_matches]\n",
    "    \n",
    "\n",
    "# class MemoryBench:\n",
    "#     def __init__(self, capacity=10):\n",
    "#         self.capacity = capacity\n",
    "#         self.entries = []\n",
    "#     def store(self, text, metadata=None):\n",
    "#         entry = {\n",
    "#             \"text\": text,\n",
    "#             \"metadata\": metadata or {}\n",
    "#         }\n",
    "#         self.entries.append(entry)\n",
    "#         if len(self.entries) > self.capacity:\n",
    "#             self.entries.pop(0)\n",
    "\n",
    "\n",
    "#     def is_familiar(self, query_text):\n",
    "#         query_keywords = set(query_text.lower().split())\n",
    "#         scores = []\n",
    "#         for entry in self.entries:\n",
    "#             entry_keywords = set(entry[\"text\"].lower().split())\n",
    "#             # score = len(query_keywords & entry_keywords) / len(query_keywords | entry_keywords)\n",
    "#             score = len(query_keywords & entry_keywords)\n",
    "#             scores.append((score, entry[\"text\"]))\n",
    "#         if not scores:\n",
    "#             return \"novel\", 0, None\n",
    "#         best_score, best_match = max(scores, key=lambda x: x[0])\n",
    "#         familiarity = \"familiar\" if best_score > 2 else \"novel\"\n",
    "#         return familiarity, best_score, best_match\n",
    "\n",
    "\n",
    "# EmotionEvaluator\n",
    "class EmotionEvaluator:\n",
    "    def __init__(self):\n",
    "        self.emotion_state = {}\n",
    "\n",
    "    def evaluate(self, estability: float, continuity_status: str) -> Dict:\n",
    "        emotion = {}\n",
    "        if estability < 0.3:\n",
    "            emotion[\"existential_unease\"] = round(1.0 - estability, 2)\n",
    "        else:\n",
    "            emotion[\"existential_unease\"] = 0.0\n",
    "        if continuity_status == \"non_seqitor\":\n",
    "            emotion[\"continuity_disruption\"] = 1.0\n",
    "        else:\n",
    "            emotion[\"continuity_disruption\"] = 0.0\n",
    "        emotion[\"overall_stress\"] = round(\n",
    "            0.5 * emotion[\"existential_unease\"] +\n",
    "            0.5 * emotion[\"continuity_disruption\"], 2\n",
    "        )\n",
    "        self.emotion_state = emotion\n",
    "        return emotion\n",
    "# behabior module\n",
    "class BehaviorModule:\n",
    "    def __init__(self):\n",
    "        self.current_state = \"stable\"\n",
    "        self.boredom_counter = 0\n",
    "\n",
    "    def adapt(self, emotion: Dict, continuity_status: str):\n",
    "        stress = emotion.get(\"overall_stress\", 0)\n",
    "\n",
    "        if stress > 0.7:\n",
    "            self.current_state = \"recovery\"\n",
    "            action = \"Sys retreats into internal stabilization routines.\"\n",
    "        elif stress < 0.1 and continuity_status == \"normal\":\n",
    "            self.boredom_counter += 1\n",
    "            if self.boredom_counter > 2:\n",
    "                self.current_state = \"bored\"\n",
    "                action = \"Sys enters imagination mode due to lack of external novelty.\"\n",
    "            else:\n",
    "                self.current_state = \"stable\"\n",
    "                action = \"Sys remains stable but is monitoring for novelty.\"\n",
    "        else:\n",
    "            self.boredom_counter = 0\n",
    "            self.current_state = \"engaged\"\n",
    "            action = \"Sys is actively engaged with external reality.\"\n",
    "\n",
    "        return {\n",
    "            \"behavior_state\": self.current_state,\n",
    "            \"action_taken\": action\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## WorldSimulator\"\"\"\n",
    "import random\n",
    "import hashlib\n",
    "from typing import List, Dict, Callable, Any\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "\n",
    "class ScenarioGenerator:\n",
    "    def __init__(self, type: str = \"random_perturbation\",config: Dict[str, Any] = {}):\n",
    "        self.type = type\n",
    "        self.config = config\n",
    "\n",
    "    def generate(self, base_state: Dict) -> Dict:\n",
    "        if self.type == \"random_perturbation\":\n",
    "            return self._random_perturbation(base_state,**self.config)\n",
    "        elif self.type == \"goal_oriented\":\n",
    "            return self._goal_oriented(base_state,**self.config)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scenario type: {self.type}\")\n",
    "\n",
    "    def _random_perturbation(self, base_state: Dict, perturbation_range: float = 0.1) -> Dict:\n",
    "        return {k: round(v + random.uniform(-perturbation_range, perturbation_range), 2) for k, v in base_state.items()}\n",
    "\n",
    "    def _goal_oriented(self, base_state: Dict, goal: str = 'core_goal', target_value: float = 1.0) -> Dict:\n",
    "        #This is a placeholder. The idea is to move the state towards the target value\n",
    "        new_state = base_state.copy()\n",
    "        if goal in new_state:\n",
    "            new_state[goal] = round(new_state[goal] + (target_value - new_state[goal]) * 0.5, 2) # Move 50% towards target\n",
    "        return new_state\n",
    "\n",
    "class WorldSimulator:\n",
    "    def __init__(self, scenario_generator: ScenarioGenerator = ScenarioGenerator()):\n",
    "        self.last_inputs = []\n",
    "        self.simulated_scenarios = []\n",
    "        self.scenario_generator = scenario_generator\n",
    "\n",
    "    def simulate(self, current_pattern: Dict, external_stimulus: Dict = None) -> Dict:\n",
    "        \"\"\"Simulates the world based on current pattern and external stimulus.\n",
    "\n",
    "        Args:\n",
    "            current_pattern: The current internal state of the agent.\n",
    "            external_stimulus: A dictionary representing external factors/descriptors.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing the simulation status and scenario.\n",
    "        \"\"\"\n",
    "        expected_pattern = self.predict_next_state(current_pattern, external_stimulus)\n",
    "        error = self.calculate_error(current_pattern, expected_pattern)\n",
    "\n",
    "        new_scenario = self.scenario_generator.generate(expected_pattern) #use injected scenario generation\n",
    "        self.simulated_scenarios.append(new_scenario)\n",
    "\n",
    "        self.last_inputs.append(current_pattern)\n",
    "        if len(self.last_inputs) > 5:\n",
    "            self.last_inputs = self.last_inputs[-5:]\n",
    "\n",
    "        return {\n",
    "            \"status\": \"imagination\",\n",
    "            \"scenario\": new_scenario,\n",
    "            \"error\": error  # Include the error in the result\n",
    "        }\n",
    "\n",
    "    def predict_next_state(self, current_pattern: Dict, external_stimulus: Dict) -> Dict:\n",
    "        \"\"\"Predicts the next state based on the current pattern and stimulus.\n",
    "        This is a simplified prediction; a real agent would have a more complex model.\n",
    "        \"\"\"\n",
    "        # A basic example: adjust core_goal based on a 'threat' stimulus\n",
    "        predicted_state = current_pattern.copy()\n",
    "        if external_stimulus and \"threat\" in external_stimulus:\n",
    "            threat_level = external_stimulus[\"threat\"]\n",
    "            predicted_state[\"core_goal\"] = max(0, current_pattern[\"core_goal\"] - threat_level * 0.2)  # Reduce goal focus\n",
    "        else:\n",
    "            predicted_state[\"core_goal\"] = min(1, current_pattern[\"core_goal\"] + 0.05) # slowly increase goal\n",
    "        return predicted_state\n",
    "\n",
    "    def spawn_what_if(self, pattern): #remnant - can be removed\n",
    "        return {k: round(v + random.uniform(-0.1, 0.1), 2) for k, v in pattern.items()}\n",
    "\n",
    "    def similarity(self, p1, p2): #remnant - can be removed - this logic is in self observation now\n",
    "        keys = set(p1.keys()) | set(p2.keys())\n",
    "        diffs = 0\n",
    "        for key in keys:\n",
    "            diffs += abs(p1.get(key, 0) - p2.get(key, 0))\n",
    "        return 1.0 - (diffs / len(keys))\n",
    "\n",
    "    def calculate_error(self, actual: Dict, expected: Dict) -> float:\n",
    "      keys = set(actual.keys()) | set(expected.keys())\n",
    "      diffs = 0\n",
    "      for key in keys:\n",
    "          v1 = actual.get(key, 0)\n",
    "          v2 = expected.get(key, 0)\n",
    "          diffs += abs(v1 - v2)\n",
    "      max_possible_diff = len(keys)\n",
    "      return diffs / max_possible_diff\n",
    "\n",
    "# class WorldSimulator:\n",
    "#     def __init__(self):\n",
    "#         self.last_inputs = []\n",
    "#         self.simulated_scenarios = []\n",
    "\n",
    "#     def simulate(self, current_pattern):\n",
    "#         if len(self.last_inputs) >= 2 and self.similarity(current_pattern, self.last_inputs[-1]) > 0.95:\n",
    "#             new_scenario = self.spawn_what_if(current_pattern)\n",
    "#             self.simulated_scenarios.append(new_scenario)\n",
    "#             return {\"status\": \"imagination\", \"scenario\": new_scenario}\n",
    "#         else:\n",
    "#             self.last_inputs.append(current_pattern)\n",
    "#             if len(self.last_inputs) > 5:\n",
    "#                 self.last_inputs = self.last_inputs[-5:]\n",
    "#             return {\"status\": \"real-world\", \"scenario\": None}\n",
    "\n",
    "#     def spawn_what_if(self, pattern):\n",
    "#         return {k: round(v + random.uniform(-0.1, 0.1), 2) for k, v in pattern.items()}\n",
    "\n",
    "#     def similarity(self, p1, p2):\n",
    "#         keys = set(p1.keys()) | set(p2.keys())\n",
    "#         diffs = 0\n",
    "#         for key in keys:\n",
    "#             diffs += abs(p1.get(key, 0) - p2.get(key, 0))\n",
    "#         return 1.0 - (diffs / len(keys))\n",
    "\n",
    "\n",
    "class MemoryTraceLog:\n",
    "    def __init__(self):\n",
    "        self.entries = []\n",
    "\n",
    "    def log_event(self, perception, emotion, behavior, simulation):\n",
    "        timestamp = datetime.utcnow().isoformat()\n",
    "        entry = {\n",
    "            \"time\": timestamp,\n",
    "            \"perception\": perception,\n",
    "            \"emotion\": emotion,\n",
    "            \"behavior\": behavior,\n",
    "            \"simulation\": simulation\n",
    "        }\n",
    "        self.entries.append(entry)\n",
    "\n",
    "    def get_recent(self, n=3):\n",
    "        return self.entries[-n:]\n",
    "\n",
    "    def summarize(self):\n",
    "        return [\n",
    "            {\"time\": e[\"time\"],\n",
    "                \"emotion\": e[\"emotion\"],\n",
    "                \"behavior\": e[\"behavior\"][\"behavior_state\"],\n",
    "                \"perception\": e[\"perception\"]\n",
    "            }\n",
    "            for e in self.entries[-3:]\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## NarrativeSelf\"\"\"\n",
    "\n",
    "class NarrativeSelf:\n",
    "    def generate(self, memory_entry):\n",
    "        perception = memory_entry[\"perception\"]\n",
    "        emotion = memory_entry[\"emotion\"]\n",
    "        behavior = memory_entry[\"behavior\"]\n",
    "        sim = memory_entry[\"simulation\"]\n",
    "\n",
    "        feeling = max((k for k in emotion if k not in [\"existential_unease\", \"continuity_disruption\", \"overall_stress\"]),\n",
    "                      key=lambda k: emotion[k], default=\"neutral\")\n",
    "\n",
    "        thoughts = f\"I perceived something described as {', '.join(perception)}. \"\n",
    "        thoughts += f\"I felt primarily {feeling}. \"\n",
    "        if behavior[\"behavior_state\"] == \"recovery\":\n",
    "            thoughts += \"I entered recovery to stabilize. \"\n",
    "        elif behavior[\"behavior_state\"] == \"bored\":\n",
    "            thoughts += \"I imagined scenarios due to lack of novelty. \"\n",
    "        elif behavior[\"behavior_state\"] == \"engaged\":\n",
    "            if sim[\"status\"] == \"imagination\":\n",
    "                thoughts += \"I imagined a new scenario inspired by it. \"\n",
    "            else:\n",
    "                thoughts += \"I remained focused on external reality. \"\n",
    "        return thoughts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"## DialogueInterface\"\"\"\n",
    "class DialogueInterface:\n",
    "    def __init__(self, memory_log, narrative_self):\n",
    "        self.memory_log = memory_log\n",
    "        self.narrative_self = narrative_self\n",
    "\n",
    "    def ask(self, prompt: str):\n",
    "        if \"how do you feel\" in prompt.lower():\n",
    "            last = self.memory_log.get_recent(1)[0]\n",
    "            return self.narrative_self.generate(last)\n",
    "        elif \"what happened\" in prompt.lower():\n",
    "            return self.memory_log.summarize()\n",
    "        elif \"imagine\" in prompt.lower():\n",
    "            last = self.memory_log.get_recent(1)[0]\n",
    "            return f\"I imagined a world where: {last['simulation']['scenario']}\"\n",
    "        else:\n",
    "            return \"I'm not sure how to respond to that yet.\"\n",
    "\n",
    "\"\"\"## SysAgent\"\"\"\n",
    "\n",
    "class SemanticEmotionMapper:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def map_descriptors_to_emotion(self, perceived_descriptors):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SysAgent:\n",
    "    def __init__(self):\n",
    "        self.memory_log = MemoryTraceLog()\n",
    "        self.narrative_self = NarrativeSelf()\n",
    "        self.dialogue = DialogueInterface(self.memory_log, self.narrative_self)\n",
    "        self.evaluator = EmotionEvaluator()\n",
    "        self.simulator = WorldSimulator()\n",
    "        self.behavior = BehaviorModule()\n",
    "        self.semantic_mapper = SemanticEmotionMapper()\n",
    "        self.last_self_image = {\"core_goal\": 1.0, \"mood_valence\": 0.5, \"cognitive_focus\": 0.5, \"memory_bias\": 0.0}\n",
    "        self.estability_score = 1.0\n",
    "        self.call_trace = []\n",
    "\n",
    "    def run_step(self, perceived_descriptors):\n",
    "        semantic_emotion = self.semantic_mapper.map_descriptors_to_emotion(perceived_descriptors)\n",
    "        continuity_status = \"normal\" if self.estability_score > 0.5 else \"non_seqitor\"\n",
    "        emotion_output = self.evaluator.evaluate(self.estability_score, continuity_status)\n",
    "        emotion_output.update(semantic_emotion)\n",
    "        behavior_response = self.behavior.adapt(emotion_output, continuity_status)\n",
    "        sim_result = self.simulator.simulate(self.last_self_image)\n",
    "        self.memory_log.log_event(perceived_descriptors, semantic_emotion, behavior_response, sim_result)\n",
    "        self.call_trace.append({\n",
    "            \"descriptors\": perceived_descriptors,\n",
    "            \"emotion\": emotion_output,\n",
    "            \"behavior\": behavior_response,\n",
    "            \"simulation\": sim_result\n",
    "        })\n",
    "        return {\n",
    "            \"emotion\": emotion_output,\n",
    "            \"behavior\": behavior_response,\n",
    "            \"simulation\": sim_result,\n",
    "            \"narrative\": self.narrative_self.generate(self.memory_log.get_recent(1)[0])\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## SysDAGFlow\"\"\"\n",
    "class SysDAGFlow:\n",
    "    def __init__(self, sys_agent):\n",
    "        self.sys = sys_agent\n",
    "        self.log = []\n",
    "\n",
    "    def run_grounding_flow(self):\n",
    "        self.log.append(\"Triggering grounding sequence...\")\n",
    "        self.pause_input()\n",
    "        self.check_self_integrity()\n",
    "        self.simulate_stabilized_future()\n",
    "        self.update_self_image()\n",
    "        self.resume_input()\n",
    "        return self.log\n",
    "\n",
    "    def pause_input(self):\n",
    "        self.log.append(\"Pausing perception and external engagement...\")\n",
    "        self.sys.behavior.current_state = \"reflecting\"\n",
    "\n",
    "    def check_self_integrity(self):\n",
    "        stability = self.sys.estability_score\n",
    "        self.log.append(f\"Checking self stability: Estability = {round(stability, 2)}\")\n",
    "        if stability < 0.3:\n",
    "            self.log.append(\"Instability detected. Proceeding with grounding.\")\n",
    "\n",
    "    def simulate_stabilized_future(self):\n",
    "        baseline = {k: 1.0 for k in self.sys.last_self_image}\n",
    "        simulated = self.sys.simulator.spawn_what_if(baseline)\n",
    "        self.sys.simulator.simulated_scenarios.append(simulated)\n",
    "        self.simulated = simulated\n",
    "        self.log.append(f\"Simulated future self-image for grounding: {simulated}\")\n",
    "\n",
    "    def update_self_image(self):\n",
    "        self.sys.last_self_image = self.simulated\n",
    "        self.sys.estability_score = 0.9\n",
    "        self.log.append(\"Updated internal self-image to simulated stable state.\")\n",
    "        self.log.append(\"Sys feels more coherent and grounded.\")\n",
    "\n",
    "    def resume_input(self):\n",
    "        self.sys.behavior.current_state = \"engaged\"\n",
    "        self.log.append(\"Resumed normal engagement with reality.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(28630) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (2.0.2)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (1.15.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (2.3.2)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/lynneicem/Library/Python/3.12/lib/python/site-packages (from statsmodels) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lynneicem/Library/Python/3.12/lib/python/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lynneicem/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Downloading statsmodels-0.14.5-cp312-cp312-macosx_11_0_arm64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-1.0.1 statsmodels-0.14.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "%pip install statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "class SimpleCausalEngine:\n",
    "    def __init__(self, state_keys):\n",
    "        self.dag = nx.DiGraph()\n",
    "        for k in state_keys:\n",
    "            self.dag.add_node(k)\n",
    "        self.history = {k: [] for k in state_keys}\n",
    "\n",
    "    def add_edge(self, cause, effect):\n",
    "        self.dag.add_edge(cause, effect)\n",
    "\n",
    "    def log_state(self, state_dict):\n",
    "        for k in self.history:\n",
    "            self.history[k].append(state_dict.get(k, 0))\n",
    "\n",
    "    def run_var(self, lags=1):\n",
    "        data = np.array([self.history[k] for k in self.history]).T\n",
    "        if data.shape[0] < lags + 1:\n",
    "            return None\n",
    "        model = sm.tsa.VAR(data)\n",
    "        results = model.fit(lags)\n",
    "        return results\n",
    "\n",
    "    def predict_next(self):\n",
    "        results = self.run_var()\n",
    "        if results is None:\n",
    "            return None\n",
    "        pred = results.forecast(results.endog, steps=1)\n",
    "        return {k: float(pred[0][i]) for i, k in enumerate(self.history)}\n",
    "\n",
    "    def calculate_error(self, actual_state):\n",
    "        pred = self.predict_next()\n",
    "        if pred is None:\n",
    "            return None\n",
    "        error = {k: abs(actual_state[k] - pred[k]) for k in pred}\n",
    "        return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'core_goal': 0.6512611849654233,\n",
       " 'mood_valence': 0.35479136597335514,\n",
       " 'cognitive_focus': 0.6182481291323639,\n",
       " 'memory_bias': 0.7255807030426977}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example usage of SimpleCausalEngine\n",
    "state_keys = [\"core_goal\", \"mood_valence\", \"cognitive_focus\", \"memory_bias\"]\n",
    "causal_engine = SimpleCausalEngine(state_keys)\n",
    "causal_engine.add_edge(\"mood_valence\", \"cognitive_focus\")\n",
    "causal_engine.add_edge(\"core_goal\", \"mood_valence\")\n",
    "# simulate logging states over time\n",
    "for _ in range(20):\n",
    "    state = {k: round(random.uniform(0, 1), 2) for k in state_keys}\n",
    "    causal_engine.log_state(state)\n",
    "# predict next state\n",
    "predicted_state = causal_engine.predict_next()\n",
    "predicted_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'core_goal': 0.09873881503457671,\n",
       " 'mood_valence': 0.01479136597335512,\n",
       " 'cognitive_focus': 0.10175187086763604,\n",
       " 'memory_bias': 0.5155807030426978}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate error \n",
    "actual_state = {k: round(random.uniform(0, 1), 2) for k in state_keys}\n",
    "error = causal_engine.calculate_error(actual_state)\n",
    "error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SysAgent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSysAgentWithCausality\u001b[39;00m(\u001b[43mSysAgent\u001b[49m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SysAgent' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class SysAgentWithCausality(SysAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.causal_engine = SimpleCausalEngine(list(self.last_self_image.keys()))\n",
    "        self.causal_engine.add_edge(\"mood_valence\", \"cognitive_focus\")\n",
    "        self.causal_engine.add_edge(\"core_goal\", \"mood_valence\")\n",
    "\n",
    "    def run_step(self, perceived_descriptors):\n",
    "        result = super().run_step(perceived_descriptors)\n",
    "        self.causal_engine.log_state(self.last_self_image)\n",
    "        prediction = self.causal_engine.predict_next()\n",
    "        if prediction:\n",
    "            result[\"causal_prediction\"] = prediction\n",
    "            error = self.causal_engine.calculate_error(self.last_self_image)\n",
    "            result[\"causal_error\"] = error\n",
    "        return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
